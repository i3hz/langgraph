{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988bd1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from typing import Any, TypedDict,Annotated, Literal\n",
    "from pydantic import BaseModel,Field\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ed4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
    "    feedback: str = Field(..., description=\"feedback for the tweet.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aa342cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\") # Specify the model here\n",
    "evaluator = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\") # Specify the model here\n",
    "optimizer = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\") # Specify the model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c5e78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm = evaluator.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetState(TypedDict):\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    tweet_history: list[str]\n",
    "    feedback_history: list[str]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff817922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "Rules:\n",
    "- Do NOT use question-answer format.\n",
    "- Max 280 characters.\n",
    "- Use observational humor, irony, sarcasm, or cultural references.\n",
    "- Think in meme logic, punchlines, or relatable takes.\n",
    "- Use simple, day to day english\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    response = generator.invoke(messages).content\n",
    "\n",
    "    return {\n",
    "        'tweet': response,\n",
    "        'tweet_history': state.get(\"tweet_history\", []) + [response]\n",
    "    }\n",
    "\n",
    "# %% Evaluate tweet\n",
    "def evaluate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Evaluate the following tweet:\n",
    "\n",
    "Tweet: \"{state['tweet']}\"\n",
    "\n",
    "Use the criteria below to evaluate the tweet:\n",
    "\n",
    "1. Originality – Is this fresh, or have you seen it a hundred times before?  \n",
    "2. Humor – Did it genuinely make you smile, laugh, or chuckle?  \n",
    "3. Punchiness – Is it short, sharp, and scroll-stopping?  \n",
    "4. Virality Potential – Would people retweet or share it?  \n",
    "5. Format – Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "Auto-reject if:\n",
    "- It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "- It exceeds 280 characters\n",
    "- It reads like a traditional setup-punchline joke\n",
    "- Don’t end with generic, throwaway, or deflating lines\n",
    "\n",
    "### Respond ONLY in structured format:\n",
    "- evaluation: \"approved\" or \"needs_improvement\"  \n",
    "- feedback: One paragraph explaining the strengths and weaknesses \n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "\n",
    "    return {\n",
    "        'evaluation': response.evaluation,\n",
    "        'feedback': response.feedback,\n",
    "        'feedback_history': state.get(\"feedback_history\", []) + [response.feedback]\n",
    "    }\n",
    "\n",
    "# %% Optimize tweet\n",
    "def optimize_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Improve the tweet based on this feedback:\n",
    "\"{state['feedback']}\"\n",
    "\n",
    "Topic: \"{state['topic']}\"\n",
    "Original Tweet:\n",
    "{state['tweet']}\n",
    "\n",
    "Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    response = optimizer.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "\n",
    "    return {\n",
    "        'tweet': response,\n",
    "        'iteration': iteration,\n",
    "        'tweet_history': state.get(\"tweet_history\", []) + [response]\n",
    "    }\n",
    "\n",
    "# %% Routing\n",
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == \"approved\" or state['iteration'] >= state['max_iterations']:\n",
    "        return END\n",
    "    else:\n",
    "        return 'optimize_tweet'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f734567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'Hogwarts professors on Twitter', 'tweet': 'Hogwarts professors on Twitter: Flitwick trying to go viral with a \"Wingardium Leviosa\" TikTok dance tutorial (too many emojis). Meanwhile, Snape\\'s burner account is just subtweeting Gryffindors and rating potion ingredients. #HogwartsOnX', 'evaluation': 'approved', 'feedback': 'This tweet demonstrates excellent originality and humor by perfectly capturing the essence of Flitwick and Snape in a modern social media context. The specific scenarios, like Flitwick\\'s \"Wingardium Leviosa\" TikTok and Snape\\'s burner account subtweeting Gryffindors, are both fresh and genuinely funny, making it highly relatable and shareable. The tweet is punchy, well-formatted, and under the character limit, ensuring strong virality potential. The use of the hashtag #HogwartsOnX is a clever touch that enhances its appeal.', 'iteration': 1, 'max_iterations': 5}\n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "\n",
    "graph.add_node('generate_tweet', generate_tweet)\n",
    "graph.add_node('evaluate_tweet', evaluate_tweet)\n",
    "graph.add_node('optimize_tweet', optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate_tweet')\n",
    "graph.add_edge('generate_tweet', 'evaluate_tweet')\n",
    "\n",
    "graph.add_conditional_edges('evaluate_tweet', route_evaluation)\n",
    "\n",
    "\n",
    "graph.add_edge('optimize_tweet', 'evaluate_tweet')\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# %% Run\n",
    "initial_state = {\n",
    "    \"topic\": \"Hogwarts professors on Twitter\",\n",
    "    \"iteration\": 1,\n",
    "    \"max_iterations\": 5,\n",
    "    \"tweet_history\": [],\n",
    "    \"feedback_history\": []\n",
    "}\n",
    "\n",
    "result = workflow.invoke(initial_state)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc36f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
